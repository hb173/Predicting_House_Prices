{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and save data for final model\n",
    "Description:  \n",
    "While fitting the models, we found some data have unnecessary columns or errorneous values that caused some models to err out dispite having cleaned the data. Here, we remove those problematic data again and save the new data to disk.  \n",
    "We also create data sets without geo info (state, county, city) so that we can test whether the model could be location-agnostic.  \n",
    "Not all data sets created in this file were used, but we created them anyway just in case we wanted to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data without Geo info\n",
    "Drop columns such as state, city, county.  \n",
    "We do this so that we can train models using data from one state and test using data from the other state.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and clean\n",
    "X_train = pd.read_csv('../Data/X_train_model2.csv')\n",
    "y_train = pd.read_csv('../Data/y_train_model2.csv')\n",
    "X_validate = pd.read_csv('../Data/X_valid_model2.csv')\n",
    "y_validate = pd.read_csv('../Data/y_valid_model2.csv')\n",
    "\n",
    "X_train_all = pd.read_csv('../Data/X_train_all.csv')\n",
    "y_train_all = pd.read_csv('../Data/y_train_all.csv')\n",
    "X_test = pd.read_csv('../Data/X_test_all.csv')\n",
    "y_test = pd.read_csv('../Data/y_test_all.csv')\n",
    "\n",
    "\n",
    "X_train.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "y_train.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "X_validate.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "y_validate.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "X_train_all.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "y_train_all.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "X_test.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "y_test.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "\n",
    "# rename this column which gives an error in LGBM because its name has quotation marks\n",
    "X_train.rename(columns={'city_\"oneals\"': 'city_oneals'}, inplace=True)\n",
    "X_validate.rename(columns={'city_\"oneals\"': 'city_oneals'}, inplace=True)\n",
    "\n",
    "X_train_all.rename(columns={'city_\"oneals\"': 'city_oneals'}, inplace=True)\n",
    "X_test.rename(columns={'city_\"oneals\"': 'city_oneals'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Geo info\n",
    "X_test_noGeo = X_test.copy()\n",
    "X_test_noGeo = X_test_noGeo[X_test_noGeo.columns.drop(list(X_test_noGeo.filter(regex='state_')))]\n",
    "X_test_noGeo = X_test_noGeo[X_test_noGeo.columns.drop(list(X_test_noGeo.filter(regex='city_')))]\n",
    "X_test_noGeo = X_test_noGeo[X_test_noGeo.columns.drop(list(X_test_noGeo.filter(regex='county_')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Geo info\n",
    "X_train_all_noGeo = X_train_all.copy()\n",
    "X_train_all_noGeo = X_train_all_noGeo[X_train_all_noGeo.columns.drop(list(X_train_all_noGeo.filter(regex='state_')))]\n",
    "X_train_all_noGeo = X_train_all_noGeo[X_train_all_noGeo.columns.drop(list(X_train_all_noGeo.filter(regex='city_')))]\n",
    "X_train_all_noGeo = X_train_all_noGeo[X_train_all_noGeo.columns.drop(list(X_train_all_noGeo.filter(regex='county_')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noGeo.to_csv('../Data/X_test_noGeo.csv')\n",
    "X_train_all_noGeo.to_csv('../Data/X_train_all_noGeo.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save modified state-level data\n",
    "We do this so that we can more easily test models on different data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod data and clean\n",
    "# training data\n",
    "X_train_GA = pd.read_csv('../Data/X_train_GA.csv')\n",
    "y_train_GA = pd.read_csv('../Data/y_train_GA.csv')\n",
    "\n",
    "X_train_GA = X_train_GA[X_train_GA.columns.drop(list(X_train_GA.filter(regex='state_')))]\n",
    "X_train_GA = X_train_GA[X_train_GA.columns.drop(list(X_train_GA.filter(regex='city_')))]\n",
    "X_train_GA = X_train_GA[X_train_GA.columns.drop(list(X_train_GA.filter(regex='county_')))]\n",
    "\n",
    "X_train_GA.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "y_train_GA.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "X_train_GA.rename(columns={'city_\"oneals\"': 'city_oneals'}, inplace=True)\n",
    "\n",
    "# test data\n",
    "X_test_GA = pd.read_csv('../Data/X_test_GA.csv')\n",
    "y_test_GA = pd.read_csv('../Data/y_test_GA.csv')\n",
    "\n",
    "X_test_GA = X_test_GA[X_test_GA.columns.drop(list(X_test_GA.filter(regex='state_')))]\n",
    "X_test_GA = X_test_GA[X_test_GA.columns.drop(list(X_test_GA.filter(regex='city_')))]\n",
    "X_test_GA = X_test_GA[X_test_GA.columns.drop(list(X_test_GA.filter(regex='county_')))]\n",
    "\n",
    "X_test_GA.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "y_test_GA.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "X_test_GA.rename(columns={'city_\"oneals\"': 'city_oneals'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and clean\n",
    "# training data\n",
    "X_train_CA = pd.read_csv('../Data/X_train_CA.csv')\n",
    "y_train_CA = pd.read_csv('../Data/y_train_CA.csv')\n",
    "\n",
    "X_train_CA = X_train_CA[X_train_CA.columns.drop(list(X_train_CA.filter(regex='state_')))]\n",
    "X_train_CA = X_train_CA[X_train_CA.columns.drop(list(X_train_CA.filter(regex='city_')))]\n",
    "X_train_CA = X_train_CA[X_train_CA.columns.drop(list(X_train_CA.filter(regex='county_')))]\n",
    "\n",
    "X_train_CA.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "y_train_CA.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "X_train_CA.rename(columns={'city_\"oneals\"': 'city_oneals'}, inplace=True)\n",
    "\n",
    "# test data\n",
    "X_test_CA = pd.read_csv('../Data/X_test_CA.csv')\n",
    "y_test_CA = pd.read_csv('../Data/y_test_CA.csv')\n",
    "\n",
    "X_test_CA = X_test_CA[X_test_CA.columns.drop(list(X_test_CA.filter(regex='state_')))]\n",
    "X_test_CA = X_test_CA[X_test_CA.columns.drop(list(X_test_CA.filter(regex='city_')))]\n",
    "X_test_CA = X_test_CA[X_test_CA.columns.drop(list(X_test_CA.filter(regex='county_')))]\n",
    "\n",
    "X_test_CA.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "y_test_CA.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "X_test_CA.rename(columns={'city_\"oneals\"': 'city_oneals'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_GA.to_csv('../Data/X_train_GA_noGeo.csv')\n",
    "X_train_CA.to_csv('../Data/X_train_CA_noGeo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data with modified column names to use in LGBM\n",
    "Some data files have unnecessary columns or columns with errors.  \n",
    "We removed those columns in the code above. We now save the data files to disk so that we can use them in subsequent modeling steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../Data/X_train_for_LGBM.csv')\n",
    "X_train_all.to_csv('../Data/X_train_all_for_LGBM.csv')\n",
    "X_test.to_csv('../Data/X_test_for_LGBM.csv')\n",
    "X_validate.to_csv(('../Data/X_validate_for_LGBM.csv'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5304ae18d49e25f84514d65bac6a749711e4958fd015312bd1e570e768ce6e0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('general')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
